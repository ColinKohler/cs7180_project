{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa952229490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import ipdb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "sys.path.append('../')\n",
    "import dataset_loader\n",
    "from rnmn import RNMN\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(9) #9=good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorToDevice(*tensors):\n",
    "    return [tensor.to(device) for tensor in tensors]\n",
    "\n",
    "def trainBatch(samples, queries, query_lens, labels):\n",
    "    model.train()\n",
    "    # Transfer data to gpu/cpu and pass through model\n",
    "    samples, queries, query_lens, labels = tensorToDevice(samples, queries, query_lens, labels)\n",
    "    output = model(queries, query_lens, samples, debug=False)\n",
    "    \n",
    "    # Compute loss & step optimzer\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(output, labels.squeeze().long())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "    \n",
    "def testBatch(samples, queries, query_lens, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Transfer data to gpu/cpu and pass through model\n",
    "        samples, queries, query_lens, labels = tensorToDevice(samples, queries, query_lens, labels)\n",
    "        output = model(queries, query_lens, samples)\n",
    "        \n",
    "        # Compute loss & acccriterionuracy\n",
    "        loss = criterion(output, labels.squeeze().long())\n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "        correct = pred.eq(labels.view_as(pred).round().long()).sum()\n",
    "    \n",
    "    return output, loss.item(), correct.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set hyperparams and load dataset\n",
    "lr = 1e-4\n",
    "hidden_size = 256\n",
    "#overliberal use of squeeze prevents setting to 1\n",
    "batch_size = 256\n",
    "epochs = 100\n",
    "\n",
    "query_lang, train_loader, test_loader = dataset_loader.createScalableShapesDataLoader('v3', batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss:0.51992 | Test Loss:0.55225 | Test Acc:0.700:  14%|█▍        | 14/100 [00:14<01:31,  1.07s/it]"
     ]
    }
   ],
   "source": [
    "# Init model\n",
    "model = RNMN(query_lang.num_words, hidden_size, device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Create TQDM progress bar\n",
    "pbar = tqdm.tqdm(total=epochs)\n",
    "pbar.set_description('Train Loss:0.0 | Train Acc:0.0 | Test Loss:0.0 | Test Acc:0.0')\n",
    "\n",
    "train_losses, test_losses, test_accs = list(), list(), list()\n",
    "for epoch in range(epochs):\n",
    "    # Train for a single epoch iterating over the minibatches\n",
    "    train_loss = 0\n",
    "    for samples, queries, query_lens, labels in train_loader:\n",
    "        train_loss += trainBatch(samples, queries, query_lens, labels)\n",
    "       \n",
    "    # Test for a single epoch iterating over the minibatches\n",
    "    test_loss, test_correct = 0, 0\n",
    "    for samples, queries, query_lens, labels in test_loader:\n",
    "        _, batch_loss, batch_correct = testBatch(samples, queries, query_lens, labels)\n",
    "        test_loss += batch_loss\n",
    "        test_correct += batch_correct\n",
    "    \n",
    "    # Bookkeeping\n",
    "    train_losses.append(train_loss / (len(train_loader.dataset) / batch_size))\n",
    "    test_losses.append(test_loss / (len(test_loader.dataset) / batch_size))\n",
    "    test_accs.append(test_correct / len(test_loader.dataset))\n",
    "    \n",
    "    # Update progress bar\n",
    "    pbar.set_description('Train Loss:{:.5f} | Test Loss:{:.5f} | Test Acc:{:.3f}'.format(\n",
    "        train_losses[-1], test_losses[-1], test_accs[-1]))\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, queries, query_lens, labels = test_loader.dataset[:256]\n",
    "output, loss, correct = testBatch(samples, queries, query_lens, labels)\n",
    "print(correct)\n",
    "print(output.round())\n",
    "#i=1; plt.title(' '.join(query_lang.decodeQuery(queries[i]))); plt.imshow(samples[i].cpu().permute(1,2,0)); plt.show(); plt.imshow(b_t[i,1].cpu().detach(), cmap='gray'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
